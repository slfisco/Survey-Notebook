{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DB AND TABLE SETUP\n",
    "import sqlite3, io, pandas as pd, base64, matplotlib.pyplot as plt, sys, os, glob, pytz, IPython.core.display as ip, plotly.express as px\n",
    "from IPython.display import display, HTML\n",
    "from datetime import datetime\n",
    "\n",
    "surveyYear = '2023'\n",
    "aboveDamOnly = True\n",
    "\n",
    "additionalFilterForAboveDam = \"AND CAST(Distance AS int) > 310\" if aboveDamOnly else \"\"\n",
    "\n",
    "surveyURIs = {'2019':'https://five.epicollect.net/api/export/entries/salmon-survey-2019?form_ref=397fba6ecc674b74836efc190840c42d_5d6f454667a28&per_page=1000',\n",
    "              '2020':'https://five.epicollect.net/api/export/entries/salmon-survey-2020?form_ref=f550ab6c4dab44f49bcc33b7c1904be9_5d6f454667a28&per_page=1000',\n",
    "              '2021':'https://five.epicollect.net/api/export/entries/salmon-survey-2021?form_ref=ad5ffedf0a3246a18934e6ec36ed9569_5d6f454667a28&per_page=1000',\n",
    "              '2022':'https://five.epicollect.net/api/export/entries/salmon-survey-2022?form_ref=d46b5d8451f8410ea407bae5c8eb9f49_5d6f454667a28&per_page=1000'}\n",
    "salmonURIs = {'2019':'https://five.epicollect.net/api/export/entries/salmon-survey-2019?form_ref=397fba6ecc674b74836efc190840c42d_5d6f509867795&per_page=1000',\n",
    "              '2020':'https://five.epicollect.net/api/export/entries/salmon-survey-2020?form_ref=f550ab6c4dab44f49bcc33b7c1904be9_5d6f509867795&per_page=1000',\n",
    "              '2021':'https://five.epicollect.net/api/export/entries/salmon-survey-2021?form_ref=ad5ffedf0a3246a18934e6ec36ed9569_5d6f509867795&per_page=1000',\n",
    "              '2022':'https://five.epicollect.net/api/export/entries/salmon-survey-2022?form_ref=d46b5d8451f8410ea407bae5c8eb9f49_5d6f509867795&per_page=1000',\n",
    "              '2023':'https://kf.kobotoolbox.org/api/v2/assets/a6dEG7tnrtwjrmituAdL5k/data/?format=json'}\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "def getFigureAsHTML():\n",
    "    IObytes = io.BytesIO()\n",
    "    plt.savefig(IObytes, format = 'png')\n",
    "    IObytes.seek(0)\n",
    "    encodedPlot = base64.b64encode(IObytes.read()).decode(\"utf-8\")\n",
    "    return '<img src=\\'data:image/png;base64,{}\\'>'.format(encodedPlot)\n",
    "\n",
    "#for running locally\n",
    "def clearPreviousReports():\n",
    "    for fileName in glob.glob('*salmonReport.html'):\n",
    "        print(f\"Previous report file exists. Deleting {fileName}\")\n",
    "        os.remove(fileName)\n",
    "\n",
    "def getSurveyStats(year):\n",
    "    dead_to_date_query = f'''\n",
    "    WITH salmon_counts AS (\n",
    "        SELECT\n",
    "            Survey_Date,\n",
    "            COALESCE(SUM(CASE WHEN Species in ('Chum', 'Coho', 'Unknown', 'Sea-run Cutthroat', 'Sea-run_Cutthroat') AND Type in ('Dead', 'Remnant') THEN Quantity END), 0) AS total_dead_salmon_count,\n",
    "            COALESCE(SUM(CASE WHEN Species in ('Chum', 'Coho', 'Unknown', 'Sea-run_Cutthroat', 'Sea-run Cutthroat') AND Type = 'Live' THEN Quantity END), 0) AS total_live_salmon_count,\n",
    "            COALESCE(SUM(CASE WHEN Species in ('Chum', 'Coho', 'Unknown', 'Sea-run_Cutthroat', 'Sea-run Cutthroat') AND Type in ('Live', 'Dead', 'Remnant') THEN Quantity END), 0) AS total_salmon_count,\n",
    "            COALESCE(SUM(CASE WHEN Species = 'Chum' AND Type in ('Dead', 'Remnant') THEN Quantity END), 0) AS dead_chum_count,\n",
    "            COALESCE(SUM(CASE WHEN Species = 'Chum' AND Type = 'Live' THEN Quantity END), 0) AS live_chum_count,\n",
    "            COALESCE(SUM(CASE WHEN Species = 'Coho' AND Type in ('Dead', 'Remnant') THEN Quantity END), 0) AS dead_coho_count,\n",
    "            COALESCE(SUM(CASE WHEN Species = 'Coho' AND Type = 'Live' THEN Quantity END), 0) AS live_coho_count,\n",
    "            COALESCE(SUM(CASE WHEN Species in ('Resident_Cutthroat', 'Sea-run_Cutthroat', 'Resident Cutthroat', 'Sea-run Cutthroat', 'Cutthroat') AND Type in ('Dead', 'Remnant') THEN Quantity END), 0) as dead_cutthroat_count,\n",
    "            COALESCE(SUM(CASE WHEN Species in ('Resident_Cutthroat', 'Sea-run_Cutthroat', 'Resident Cutthroat', 'Sea-run Cutthroat', 'Cutthroat') AND Type = 'Live' THEN Quantity END), 0) as live_cutthroat_count,\n",
    "            COALESCE(SUM(CASE WHEN Species = 'Unknown' AND Type in ('Dead', 'Remnant') THEN quantity END), 0) AS dead_unknown_count,\n",
    "            COALESCE(SUM(CASE WHEN Species = 'Unknown' AND Type = 'Live' THEN quantity END), 0) AS live_unknown_count,\n",
    "            COALESCE(SUM(CASE WHEN Type = 'Redd' THEN Quantity END), 0) as redd_count\n",
    "        FROM\n",
    "            salmon\n",
    "        WHERE\n",
    "            year = {year} {additionalFilterForAboveDam}\n",
    "        GROUP BY\n",
    "            Survey_Date\n",
    "    ), running_counts AS (\n",
    "        SELECT\n",
    "            Survey_Date,\n",
    "            SUM(dead_chum_count) OVER (ORDER BY Survey_Date) AS running_total_dead_chum,\n",
    "            SUM(dead_chum_count) OVER (ORDER BY Survey_Date) + live_chum_count AS running_total_all_chum,\n",
    "            SUM(dead_coho_count) OVER (ORDER BY Survey_Date) AS running_total_dead_coho,\n",
    "            SUM(dead_coho_count) OVER (ORDER BY Survey_Date) + live_coho_count AS running_total_all_coho,\n",
    "            SUM(dead_cutthroat_count) OVER (ORDER BY Survey_Date) AS running_total_dead_cutthroat,\n",
    "            SUM(dead_cutthroat_count) OVER (ORDER BY Survey_Date) + live_cutthroat_count AS running_total_all_cutthroat,\n",
    "            SUM(dead_unknown_count) OVER (ORDER BY Survey_Date) AS running_total_dead_unknown,\n",
    "            SUM(dead_unknown_count) OVER (ORDER BY Survey_Date) + live_unknown_count AS running_total_all_unknown,\n",
    "            SUM(total_dead_salmon_count) OVER (ORDER BY Survey_Date) AS running_total_dead_salmon,\n",
    "            SUM(total_dead_salmon_count) OVER (ORDER BY Survey_Date) + total_live_salmon_count AS running_total_all_salmon\n",
    "        FROM\n",
    "            salmon_counts\n",
    "    )\n",
    "    SELECT        \n",
    "        sc.Survey_Date,\n",
    "        sc.total_dead_salmon_count,\n",
    "        sc.total_live_salmon_count,\n",
    "        sc.total_salmon_count,\n",
    "        sc.dead_chum_count,\n",
    "        sc.live_chum_count,\n",
    "        sc.dead_coho_count,\n",
    "        sc.live_coho_count,\n",
    "        sc.dead_cutthroat_count,\n",
    "        sc.live_cutthroat_count,\n",
    "        sc.dead_unknown_count,\n",
    "        sc.live_unknown_count,\n",
    "        sc.redd_count,\n",
    "        rc.running_total_dead_chum,\n",
    "        rc.running_total_all_chum,\n",
    "        rc.running_total_dead_coho,\n",
    "        rc.running_total_all_coho,\n",
    "        rc.running_total_dead_cutthroat,\n",
    "        rc.running_total_all_cutthroat,\n",
    "        rc.running_total_dead_unknown,\n",
    "        rc.running_total_all_unknown,\n",
    "        rc.running_total_dead_salmon,\n",
    "        rc.running_total_all_salmon\n",
    "    FROM\n",
    "        salmon_counts sc\n",
    "    JOIN running_counts rc ON sc.Survey_Date = rc.Survey_Date;\n",
    "    '''\n",
    "    return pd.read_sql(dead_to_date_query, connection)\n",
    "\n",
    "def getScatterMap(df, figureTitle):\n",
    "    fig = px.scatter_mapbox(df, lat='Latitude', lon='Longitude', color='Type', labels={'Type':'Type'}, color_discrete_map={'Live': 'teal', 'Redd': 'red', 'Dead': 'black'},\n",
    "                    center=dict(lat=47.71157, lon=-122.3759), zoom=15, hover_name = 'Type', hover_data = ['Distance', 'Quantity', 'Species', 'Sex', 'Accuracy'],\n",
    "                    mapbox_style='open-street-map', title=figureTitle)\n",
    "    fig.layout.coloraxis.showscale = False\n",
    "    fig.update_layout(title_x=0.5)\n",
    "    fig.show()\n",
    "    return fig.to_html(include_plotlyjs=\"cdn\")\n",
    "            \n",
    "create_salmon_table_query = '''\n",
    "    CREATE TABLE IF NOT EXISTS salmon (\n",
    "        _id STRING PRIMARY KEY,\n",
    "        Survey_Date DATE,\n",
    "        year DATE,\n",
    "        Quantity INTEGER,\n",
    "        Distance INTEGER,\n",
    "        Stream TEXT,\n",
    "        Type TEXT,\n",
    "        Species TEXT,\n",
    "        Predation TEXT,\n",
    "        Length FLOAT,\n",
    "        Width FLOAT,\n",
    "        Spawned TEXT,\n",
    "        Sex TEXT,\n",
    "        Latitude FLOAT,\n",
    "        Longitude FLOAT,\n",
    "        Accuracy FLOAT\n",
    "    );\n",
    "'''\n",
    "def getAllFiles():\n",
    "    !git clone https://github.com/slfisco/Survey-Notebook.git\n",
    "\n",
    "if IN_COLAB:\n",
    "    getAllFiles()\n",
    "else:\n",
    "    clearPreviousReports()\n",
    "reddsTable = yearByYearCountPlot = countPlot = surveyStatsTable = yearScatterMap = latestScatterMap = None\n",
    "maxSurveyChum = maxSurveyChumDate = maxSurveyCoho = maxSurveyCohoDate = chumSpawnSuccess = cohoSpawnSuccess = None   \n",
    "connection = sqlite3.connect(\":memory:\")\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(create_salmon_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA LOADING\n",
    "import requests\n",
    "\n",
    "salmon_insert_query = '''\n",
    "        INSERT OR IGNORE INTO salmon (\n",
    "        _id,\n",
    "        Survey_Date,\n",
    "        year,\n",
    "        Quantity,\n",
    "        Distance,\n",
    "        Stream,\n",
    "        Type,\n",
    "        Species,\n",
    "        Predation,\n",
    "        Length,\n",
    "        Width,\n",
    "        Spawned,\n",
    "        Sex,\n",
    "        Latitude,\n",
    "        Longitude,\n",
    "        Accuracy\n",
    "        ) VALUES (?, ?, ?, COALESCE(?,1), ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\n",
    "    '''\n",
    "\n",
    "def getData(uri):\n",
    "    response = requests.get(uri)\n",
    "    return response.json()\n",
    "\n",
    "## for epicollect data to associate salmon to a survey date\n",
    "def getSurveyDates(uri):\n",
    "    surveyDates = {}\n",
    "    data = getData(uri)\n",
    "    for entry in data['data']['entries']:\n",
    "        surveyDate = datetime.strptime(entry['Survey_Date'], \"%m/%d/%Y\").strftime(\"%Y-%m-%d\")\n",
    "        surveyDates[entry['ec5_uuid']] = surveyDate\n",
    "    return surveyDates\n",
    "    \n",
    "def getLocation(entry, isEpicollect):\n",
    "    latitude = longitude = accuracy = location = None\n",
    "    if isEpicollect:\n",
    "        latitude = entry.get('Location').get('latitude')\n",
    "        longitude = entry.get('Location').get('longitude')\n",
    "        accuracy = entry.get('Location').get('accuracy')\n",
    "    else:\n",
    "        location = entry.get('Location')\n",
    "        if location is not None: \n",
    "            location = location.split()\n",
    "            latitude = location[0]\n",
    "            longitude = location[1]\n",
    "            accuracy = location[3]\n",
    "    return latitude, longitude, accuracy\n",
    "        \n",
    "def processEntries(entries, isEpicollect, year, surveyDates):\n",
    "    for entry in entries:\n",
    "        location = getLocation(entry, isEpicollect)\n",
    "        latitude = location[0]\n",
    "        longitude = location[1]\n",
    "        accuracy = location[2]\n",
    "        values = (\n",
    "            entry.get('ec5_uuid') if isEpicollect else entry.get('_id'),\n",
    "            surveyDates[entry.get('ec5_parent_uuid')] if isEpicollect else entry.get('Survey_Date'),\n",
    "            year,\n",
    "            entry.get('Quantity', 1),\n",
    "            entry.get('Distance'),\n",
    "            entry.get('Stream'),\n",
    "            entry.get('Type'),\n",
    "            entry.get('Species'),\n",
    "            entry.get('Predation'),\n",
    "            entry.get('Length_Inches') if isEpicollect else entry.get(\"Length\"),\n",
    "            entry.get('Width_Inches') if isEpicollect else entry.get(\"Width\"),\n",
    "            entry.get('Spawning_Success') if isEpicollect else entry.get(\"Spawned\"),\n",
    "            entry.get('Sex'),\n",
    "            latitude,\n",
    "            longitude,\n",
    "            accuracy\n",
    "        )\n",
    "        cursor.execute(salmon_insert_query, values)\n",
    "        \n",
    "def loadSurveyYear(year):\n",
    "    print(f'loading for year: {year}')\n",
    "    uri = salmonURIs[year]\n",
    "    isEpicollect = \"epicollect\" in uri\n",
    "    surveyDates = getSurveyDates(surveyURIs[year]) if isEpicollect else None\n",
    "    allDataInserted = False\n",
    "    while not allDataInserted:\n",
    "        data = getData(uri)\n",
    "        entries = data['data']['entries'] if isEpicollect else data['results']\n",
    "        processEntries(entries, isEpicollect, year, surveyDates)\n",
    "        uri = data['links']['next'] if isEpicollect else data['next']\n",
    "        allDataInserted = True if uri is None else False\n",
    "        \n",
    "print('loading salmon into database')        \n",
    "for year in salmonURIs:\n",
    "    loadSurveyYear(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getMaxSurveyTotal(df, columnName):\n",
    "    max_row = df[columnName].values.argmax()\n",
    "    total = df.iloc[max_row][columnName]\n",
    "    return total\n",
    "\n",
    "def getMaxSurveyDate(df, columnName):\n",
    "    max_row = df[columnName].values.argmax()\n",
    "    calcDate = df.iloc[max_row][\"Survey_Date\"]\n",
    "    return calcDate\n",
    "    \n",
    "df = getSurveyStats(surveyYear)\n",
    "maxSurveyChum = getMaxSurveyTotal(df, 'running_total_all_chum')\n",
    "maxSurveyChumDate = getMaxSurveyDate(df, 'running_total_all_chum')\n",
    "maxSurveyCoho = getMaxSurveyTotal(df, 'running_total_all_coho')\n",
    "maxSurveyCohoDate = getMaxSurveyDate(df, 'running_total_all_coho')\n",
    "print(f'max survey chum: {maxSurveyChum}')\n",
    "print(f'max survey chum date: {maxSurveyChumDate}')\n",
    "print(f'max survey coho: {maxSurveyCoho}')\n",
    "print(f'max survey coho date: {maxSurveyCohoDate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaySurveyStatsTable():\n",
    "    tableDf = getSurveyStats(surveyYear)[['Survey_Date', 'live_chum_count', 'dead_chum_count', 'live_coho_count', 'dead_coho_count', 'live_cutthroat_count', 'dead_cutthroat_count', 'live_unknown_count', 'dead_unknown_count']]\n",
    "    table = tableDf.rename(columns={'Survey_Date': 'Survey Date', 'live_chum_count': 'Live Chum', 'dead_chum_count': 'Dead Chum', 'live_coho_count': 'Live Coho', 'dead_coho_count': 'Dead Coho', 'live_cutthroat_count': 'Live Cutthroat', 'dead_cutthroat_count': 'Dead Cutthroat', 'live_unknown_count': 'Live Unknown', 'dead_unknown_count': 'Dead Unknown'}).style.hide_index().render()\n",
    "    display(ip.HTML(table))\n",
    "    return table\n",
    "surveyStatsTable = displaySurveyStatsTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def displayCountPlot(df):\n",
    "    df['Survey_Date'] = pd.to_datetime(df['Survey_Date'])\n",
    "    plot = df.plot(ylabel = 'Count', xlabel = 'Survey Date', title = f'{surveyYear} Fish Count', rot=45, xticks=df['Survey_Date'], y=['total_dead_salmon_count', 'total_live_salmon_count', 'live_chum_count', 'dead_chum_count', 'live_coho_count', 'dead_coho_count'], x='Survey_Date')\n",
    "    plot.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "    plot.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    return getFigureAsHTML()\n",
    "countPlot = displayCountPlot(getSurveyStats(surveyYear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### REDDS TABLE. USED TO HELP SURVEY TEAM AVOID REDDS\n",
    "# redds_table_query = f'''\n",
    "# SELECT\n",
    "#     Stream, Distance, Survey_Date\n",
    "# FROM\n",
    "#     salmon\n",
    "# WHERE Type = 'Redd' AND year = {surveyYear}\n",
    "# '''\n",
    "# def createReddsTable():\n",
    "#     table = pd.read_sql(redds_table_query, connection).style.hide_index().render()\n",
    "#     display(ip.HTML(table))\n",
    "#     return table\n",
    "# reddsTable = createReddsTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### SPAWN SUCCESS\n",
    "# def plotSpawnSuccess(species):\n",
    "#     spawning_query = f'''\n",
    "#     SELECT\n",
    "#         CAST(COUNT(CASE WHEN Species = '{species}' AND Type = 'Dead' AND Spawned = 'Spawned' THEN _id END) AS float) / CAST(COUNT(CASE WHEN Species = '{species}' AND Type = 'Dead' THEN _id END) AS float) AS spawned_{species}_ratio,\n",
    "#         CAST(COUNT(CASE WHEN Species = '{species}' AND Type = 'Dead' AND Spawned = 'Unspawned' THEN _id END) AS float) / CAST(COUNT(CASE WHEN Species = '{species}' AND Type = 'Dead' THEN _id END) AS float) AS unspawned_{species}_ratio,\n",
    "#         CAST(COUNT(CASE WHEN Species = '{species}' AND Type = 'Dead' AND Spawned in ('Partially_spawned', 'Partially spawned') THEN _id END) AS float) / CAST(COUNT(CASE WHEN Species = '{species}' AND Type = 'Dead' THEN _id END) AS float) AS partial_spawn_{species}_ratio,\n",
    "#         CAST(COUNT(CASE WHEN Species = '{species}' AND Type = 'Dead' AND Spawned = 'Unknown' THEN _id END) AS float) / CAST(COUNT(CASE WHEN Species = '{species}' AND Type = 'Dead' THEN _id END) AS float) AS unknown_spawn_{species}_ratio\n",
    "#     FROM\n",
    "#         salmon\n",
    "#     WHERE year = {surveyYear}\n",
    "#     '''\n",
    "#     df = pd.read_sql(spawning_query, connection)\n",
    "#     display(ip.HTML(df.to_html(index=False)))\n",
    "#     ax = df.plot(kind='barh', stacked=True)\n",
    "#     return getFigureAsHTML()\n",
    "# chumSpawnSuccess = plotSpawnSuccess('Chum')\n",
    "# cohoSpawnSuccess = plotSpawnSuccess('Coho')\n",
    "# # todo: fix these to same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## USER INPUT QUERY\n",
    "# done = False\n",
    "# while not done:\n",
    "#     try:\n",
    "#         query = input(\"Enter a query: \")\n",
    "#         print(\"entering query: \" + query)\n",
    "#         cursor.execute(query)\n",
    "#         print(cursor.fetchall())\n",
    "#     except sqlite3.Error as e:\n",
    "#         print(\"SQLite error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "class TestNotebook(unittest.TestCase):\n",
    "    def testYearlyTotals(self):\n",
    "        actual = getSurveyStats('2021').tail(1)\n",
    "        # compare 2021 yearly totals with expected values\n",
    "        self.assertEqual(actual['running_total_all_salmon'].item(), 1008)\n",
    "        self.assertEqual(actual['running_total_all_chum'].item(), 939)\n",
    "        self.assertEqual(actual['running_total_all_coho'].item(), 66)\n",
    "        self.assertEqual(actual['Survey_Date'].item(), '2021-12-07')\n",
    "    def testSurveyStats(self):\n",
    "        # compare 2021-11-16 against expected\n",
    "        actual = getSurveyStats('2021').query('`Survey_Date` == \"2021-11-16\"')\n",
    "        self.assertEqual(actual['dead_chum_count'].item(), 114)\n",
    "        self.assertEqual(actual['dead_coho_count'].item(), 29)\n",
    "        self.assertEqual(actual['live_chum_count'].item(), 447)\n",
    "        self.assertEqual(actual['live_coho_count'].item(), 2)\n",
    "        self.assertEqual(actual['live_cutthroat_count'].item(), 2)\n",
    "        self.assertEqual(actual['redd_count'].item(), 39)\n",
    "        self.assertEqual(actual['total_dead_salmon_count'].item(), 143)\n",
    "        self.assertEqual(actual['total_live_salmon_count'].item(), 451)\n",
    "        self.assertEqual(actual['running_total_dead_salmon'].item(), 277)\n",
    "        self.assertEqual(actual['running_total_dead_chum'].item(), 222)\n",
    "        self.assertEqual(actual['running_total_dead_coho'].item(), 52)\n",
    "if not aboveDamOnly: unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "def plotSeries(year):\n",
    "    statsDf = getSurveyStats(year)\n",
    "    statsDf['Survey_Date'] = statsDf['Survey_Date'].apply(lambda x: datetime.strptime(date.fromisoformat(x).strftime(\"%m-%d\"),\"%m-%d\"))\n",
    "    plt.plot('Survey_Date', 'total_salmon_count', data=statsDf, label=year)\n",
    "def getYearByYearCountPlot():\n",
    "    fig, ax = plt.subplots()\n",
    "    for year in salmonURIs:\n",
    "        plotSeries(year)\n",
    "    plt.title('Count by time of year')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Survey Date')\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "    return getFigureAsHTML()\n",
    "yearByYearCountPlot = getYearByYearCountPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## ALL SURVEYS SCATTER MAP\n",
    "query = f'''\n",
    "SELECT\n",
    "    Survey_Date, Type, Species, Latitude, Longitude, Accuracy, Distance, Sex, Quantity\n",
    "FROM\n",
    "    salmon\n",
    "WHERE Latitude IS NOT NULL AND Accuracy < 50 AND year = {surveyYear} {additionalFilterForAboveDam}\n",
    "'''\n",
    "df = pd.read_sql(query, connection)\n",
    "yearScatterMap = getScatterMap(df, f'{surveyYear} Fish Scatter Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##LATEST SURVEY SCATTER MAP\n",
    "query = f'''\n",
    "SELECT\n",
    "    Survey_Date, Type, Species, Latitude, Longitude, Accuracy, Distance, Sex, Quantity\n",
    "FROM\n",
    "    salmon\n",
    "WHERE Latitude IS NOT NULL AND Accuracy < 50 AND year = {surveyYear} AND Survey_Date = (SELECT MAX(Survey_Date) FROM salmon WHERE year = {surveyYear}) {additionalFilterForAboveDam};\n",
    "'''\n",
    "df = pd.read_sql(query, connection)\n",
    "latestSurvey = df.iloc[0]['Survey_Date']\n",
    "latestScatterMap = getScatterMap(df, f'{latestSurvey} Fish Scatter Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE REPORT WITH WHICHEVER FIGURES WERE CREATED\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "def generateReport():\n",
    "    currentTimePacific = datetime.now(pytz.timezone('America/Los_Angeles')).strftime('%Y-%m-%d_%H-%M-%S') #cannot use system time due to colab\n",
    "    reportFileName = currentTimePacific + '_salmonReport.html'\n",
    "    if IN_COLAB:\n",
    "        templatePath = 'Survey-Notebook/templates'\n",
    "    else:\n",
    "        templatePath = 'templates'\n",
    "    env = Environment(loader=FileSystemLoader(templatePath))\n",
    "    template = env.get_template('report_template.html')\n",
    "    reportData = {}\n",
    "    reportData['reportGenTime'] = currentTimePacific\n",
    "    reportData['reddsTable'] = reddsTable\n",
    "    reportData['yearByYearCountPlot'] = yearByYearCountPlot\n",
    "    reportData['countPlot'] = countPlot\n",
    "    reportData['surveyStatsTable'] = surveyStatsTable\n",
    "    reportData['yearScatterMap'] = yearScatterMap\n",
    "    reportData['latestScatterMap'] = latestScatterMap\n",
    "    reportData['maxSurveyChum'] = maxSurveyChum\n",
    "    reportData['maxSurveyChumDate'] = maxSurveyChumDate\n",
    "    reportData['maxSurveyCoho'] = maxSurveyCoho\n",
    "    reportData['maxSurveyCohoDate'] = maxSurveyCohoDate\n",
    "    reportData['chumSpawnSuccess'] = chumSpawnSuccess\n",
    "    reportData['cohoSpawnSuccess'] = cohoSpawnSuccess\n",
    "    html = template.render(reportData)\n",
    "    with open(reportFileName, 'w') as f:\n",
    "        f.write(html)\n",
    "generateReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download HTML report if in google colab\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    files.download(reportFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
